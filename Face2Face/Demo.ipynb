{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import cv2\n",
    "\n",
    "import dlib\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from imutils import video\n",
    "\n",
    "\n",
    "\n",
    "CROP_SIZE = 256\n",
    "\n",
    "DOWNSAMPLE_RATIO = 4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def reshape_for_polyline(array):\n",
    "\n",
    "    \"\"\"Reshape image so that it works with polyline.\"\"\"\n",
    "\n",
    "    return np.array(array, np.int32).reshape((-1, 1, 2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def resize(image):\n",
    "\n",
    "    \"\"\"Crop and resize image for pix2pix.\"\"\"\n",
    "\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    if height != width:\n",
    "\n",
    "        # crop to correct ratio\n",
    "\n",
    "        size = min(height, width)\n",
    "\n",
    "        oh = (height - size) // 2\n",
    "\n",
    "        ow = (width - size) // 2\n",
    "\n",
    "        cropped_image = image[oh:(oh + size), ow:(ow + size)]\n",
    "\n",
    "        image_resize = cv2.resize(cropped_image, (CROP_SIZE, CROP_SIZE))\n",
    "\n",
    "        return image_resize\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_graph(frozen_graph_filename):\n",
    "\n",
    "    \"\"\"Load a (frozen) Tensorflow model into memory.\"\"\"\n",
    "\n",
    "    graph = tf.Graph()\n",
    "\n",
    "    with graph.as_default():\n",
    "\n",
    "        od_graph_def = tf.GraphDef()\n",
    "\n",
    "        with tf.gfile.GFile(frozen_graph_filename, 'rb') as fid:\n",
    "\n",
    "            serialized_graph = fid.read()\n",
    "\n",
    "            od_graph_def.ParseFromString(serialized_graph)\n",
    "\n",
    "            tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "    return graph\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    # TensorFlow\n",
    "\n",
    "    graph = load_graph(\"C:/Users/Thiya/Desktop/Wayne/Sofwerx/Project/frozen_model.pb\")\n",
    "\n",
    "    image_tensor = graph.get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "    output_tensor = graph.get_tensor_by_name('generate_output/output:0')\n",
    "\n",
    "    sess = tf.Session(graph=graph)\n",
    "\n",
    "\n",
    "\n",
    "    # OpenCV\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    fps = video.FPS().start()\n",
    "\n",
    "\n",
    "\n",
    "    while True:\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "\n",
    "\n",
    "        # resize image and detect face\n",
    "\n",
    "        frame_resize = cv2.resize(frame, None, fx=1 / DOWNSAMPLE_RATIO, fy=1 / DOWNSAMPLE_RATIO)\n",
    "\n",
    "        gray = cv2.cvtColor(frame_resize, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        faces = detector(gray, 1)\n",
    "\n",
    "        black_image = np.zeros(frame.shape, np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "        for face in faces:\n",
    "\n",
    "            detected_landmarks = predictor(gray, face).parts()\n",
    "\n",
    "            landmarks = [[p.x * DOWNSAMPLE_RATIO, p.y * DOWNSAMPLE_RATIO] for p in detected_landmarks]\n",
    "\n",
    "\n",
    "\n",
    "            jaw = reshape_for_polyline(landmarks[0:17])\n",
    "\n",
    "            left_eyebrow = reshape_for_polyline(landmarks[22:27])\n",
    "\n",
    "            right_eyebrow = reshape_for_polyline(landmarks[17:22])\n",
    "\n",
    "            nose_bridge = reshape_for_polyline(landmarks[27:31])\n",
    "\n",
    "            lower_nose = reshape_for_polyline(landmarks[30:35])\n",
    "\n",
    "            left_eye = reshape_for_polyline(landmarks[42:48])\n",
    "\n",
    "            right_eye = reshape_for_polyline(landmarks[36:42])\n",
    "\n",
    "            outer_lip = reshape_for_polyline(landmarks[48:60])\n",
    "\n",
    "            inner_lip = reshape_for_polyline(landmarks[60:68])\n",
    "\n",
    "\n",
    "\n",
    "            color = (255, 255, 255)\n",
    "\n",
    "            thickness = 3\n",
    "\n",
    "\n",
    "\n",
    "            cv2.polylines(black_image, [jaw], False, color, thickness)\n",
    "\n",
    "            cv2.polylines(black_image, [left_eyebrow], False, color, thickness)\n",
    "\n",
    "            cv2.polylines(black_image, [right_eyebrow], False, color, thickness)\n",
    "\n",
    "            cv2.polylines(black_image, [nose_bridge], False, color, thickness)\n",
    "\n",
    "            cv2.polylines(black_image, [lower_nose], True, color, thickness)\n",
    "\n",
    "            cv2.polylines(black_image, [left_eye], True, color, thickness)\n",
    "\n",
    "            cv2.polylines(black_image, [right_eye], True, color, thickness)\n",
    "\n",
    "            cv2.polylines(black_image, [outer_lip], True, color, thickness)\n",
    "\n",
    "            cv2.polylines(black_image, [inner_lip], True, color, thickness)\n",
    "\n",
    "\n",
    "\n",
    "        # generate prediction\n",
    "\n",
    "        combined_image = np.concatenate([resize(black_image), resize(frame_resize)], axis=1)\n",
    "\n",
    "        image_rgb = cv2.cvtColor(combined_image, cv2.COLOR_BGR2RGB)  # OpenCV uses BGR instead of RGB\n",
    "\n",
    "        generated_image = sess.run(output_tensor, feed_dict={image_tensor: image_rgb})\n",
    "\n",
    "        image_bgr = cv2.cvtColor(np.squeeze(generated_image), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        image_normal = np.concatenate([resize(frame_resize), image_bgr], axis=1)\n",
    "\n",
    "        image_landmark = np.concatenate([resize(black_image), image_bgr], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "        if 0 == 0:\n",
    "\n",
    "            cv2.imshow('frame', image_normal)\n",
    "\n",
    "        else:\n",
    "\n",
    "            cv2.imshow('frame', image_landmark)\n",
    "\n",
    "\n",
    "\n",
    "        fps.update()\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "    fps.stop()\n",
    "\n",
    "    print('[INFO] elapsed time (total): {:.2f}'.format(fps.elapsed()))\n",
    "\n",
    "    print('[INFO] approx. FPS: {:.2f}'.format(fps.fps()))\n",
    "\n",
    "\n",
    "\n",
    "    sess.close()\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('-src', '--source', dest='video_source', type=int,\n",
    "\n",
    "                        default=0, help='Device index of the camera.')\n",
    "\n",
    "    parser.add_argument('--show', dest='display_landmark', type=int, default=0, choices=[0, 1],\n",
    "\n",
    "                        help='0 shows the normal input and 1 the facial landmark.')\n",
    "\n",
    "    parser.add_argument('--landmark-model', dest='face_landmark_shape_file', type=str, help='Face landmark model file.')\n",
    "\n",
    "    parser.add_argument('--tf-model', dest='frozen_model_file', type=str, help='Frozen TensorFlow model file.')\n",
    "\n",
    "\n",
    "\n",
    "    args = parser.parse_known_args()\n",
    "\n",
    "\n",
    "\n",
    "    # Create the face predictor and landmark predictor\n",
    "\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "    predictor = dlib.shape_predictor(\"C:/Users/Thiya/Desktop/Wayne/Sofwerx/Project/shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
