{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thiya\\Anaconda2\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_output/output\n",
      "WARNING:tensorflow:From C:\\Users\\Thiya\\Anaconda2\\lib\\site-packages\\tensorflow\\python\\training\\queue_runner_impl.py:391: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Restoring parameters from C:/Users/Thiya/Desktop/Wayne/Sofwerx/Project/photos1/face2face_reduced/reduced_model\n",
      "INFO:tensorflow:Froze 44 variables.\n",
      "INFO:tensorflow:Converted 44 variables to const ops.\n",
      "511 ops in the final graph.\n"
     ]
    }
   ],
   "source": [
    "import os, argparse\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.framework import graph_util\n",
    "\n",
    "\n",
    "\n",
    "dir = os.path.dirname(\"C:/Users/Thiya/Desktop/Wayne/Sofwerx/Project/photos1/face2face_reduced\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def freeze_graph(model_folder):\n",
    "\n",
    "    # We retrieve our checkpoint fullpath\n",
    "    import pdb\n",
    "    \n",
    "\n",
    "    checkpoint = tf.train.get_checkpoint_state(model_folder)\n",
    "    \n",
    "\n",
    "    input_checkpoint = checkpoint.model_checkpoint_path\n",
    "\n",
    "    input_checkpoint = input_checkpoint.replace('//', '/')\n",
    "\n",
    "    # We precise the file fullname of our freezed graph\n",
    "\n",
    "    absolute_model_folder = '/'.join(input_checkpoint.split('/')[:-1])\n",
    "    \n",
    "\n",
    "    output_graph = absolute_model_folder + '/frozen_model.pb'\n",
    "\n",
    "\n",
    "\n",
    "    # Before exporting our graph, we need to precise what is our output node\n",
    "\n",
    "    # This is how TF decides what part of the Graph he has to keep and what part it can dump\n",
    "\n",
    "    # NOTE: this variable is plural, because you can have multiple output nodes\n",
    "\n",
    "    output_node_names ='generate_output/output'\n",
    "\n",
    "    print(output_node_names)\n",
    "\n",
    "    # We clear devices to allow TensorFlow to control on which device it will load operations\n",
    "\n",
    "    clear_devices = True\n",
    "\n",
    "\n",
    "\n",
    "    # We import the meta graph and retrieve a Saver\n",
    "\n",
    "    saver = tf.train.import_meta_graph(input_checkpoint + '.meta', clear_devices=clear_devices)\n",
    "\n",
    "\n",
    "    \n",
    "    # We retrieve the protobuf graph definition\n",
    "\n",
    "    graph = tf.get_default_graph()\n",
    "\n",
    "    input_graph_def = graph.as_graph_def()\n",
    "    \n",
    "    #pdb.set_trace()\n",
    "\n",
    "    # We start a session and restore the graph weights\n",
    "\n",
    "    init_g = tf.global_variables_initializer()\n",
    "    init_l = tf.local_variables_initializer()\n",
    "\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_g)\n",
    "        sess.run(init_l)\n",
    "        saver.restore(sess,input_checkpoint)\n",
    "\n",
    "  \n",
    "\n",
    "        # We use a built-in TF helper to export variables to constants\n",
    "        \n",
    "        output_graph_def = graph_util.convert_variables_to_constants(\n",
    "\n",
    "            sess,  # The session is used to retrieve the weights\n",
    "\n",
    "            input_graph_def,  # The graph_def is used to retrieve the nodes\n",
    "\n",
    "            [output_node_names] #.split(\",\")  # The output node names are used to select the usefull nodes\n",
    "\n",
    "        )\n",
    "\n",
    "       \n",
    "\n",
    "        # Finally we serialize and dump the output graph to the filesystem\n",
    "\n",
    "        with tf.gfile.GFile(output_graph, 'wb') as f:\n",
    "\n",
    "            f.write(output_graph_def.SerializeToString())\n",
    "\n",
    "        print('%d ops in the final graph.' % len(output_graph_def.node))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--model-folder', type=str, help='Model folder to export')\n",
    "\n",
    "    args = parser.parse_known_args()\n",
    "\n",
    "    \n",
    "    freeze_graph(\"C:/Users/Thiya/Desktop/Wayne/Sofwerx/Project/photos1/face2face_reduced/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
